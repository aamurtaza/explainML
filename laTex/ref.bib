%%%






%%%%%%%%%%%%%%%%%%%%%% Books and Reads
@article{mueller2019explanation,
	title={Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI},
	author={Mueller, Shane T and Hoffman, Robert R and Clancey, William and Emrey, Abigail and Klein, Gary},
	journal={arXiv preprint arXiv:1902.01876},
	year={2019}
} % https://arxiv.org/abs/1902.01876v1

@article{rosenfeld2019explainability,
	title={Explainability in human--agent systems},
	author={Rosenfeld, Avi and Richardson, Ariella},
	journal={Autonomous Agents and Multi-Agent Systems},
	pages={1--33},
	year={2019},
	publisher={Springer}
} % https://arxiv.org/abs/1904.08123v1

@inproceedings{gilpin2018explaining,
	title={Explaining explanations: An overview of interpretability of machine learning},
	author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
	pages={80--89},
	year={2018},
	organization={IEEE}
} % https://arxiv.org/abs/1806.00069v3

@article{blandfort2018overview,
	title={An overview of computational approaches for analyzing interpretation},
	author={Blandfort, Philipp and Hees, J{\"o}rn and Patton, Desmond U},
	journal={arXiv preprint arXiv:1811.04028},
	year={2018}
} % https://arxiv.org/abs/1811.04028v2

@article{miller2018explanation,
	title={Explanation in artificial intelligence: Insights from the social sciences},
	author={Miller, Tim},
	journal={Artificial Intelligence},
	year={2018},
	publisher={Elsevier}
} % https://arxiv.org/abs/1706.07269

@article{lipton2016mythos,
	title={The mythos of model interpretability},
	author={Lipton, Zachary C},
	journal={arXiv preprint arXiv:1606.03490},
	year={2016}
} % https://arxiv.org/abs/1606.03490

@misc{molnarinterpretable,
	title={Interpretable machine learning. a guide for making black box models explainable.},
	author={Molnar, C},
	year={2018}
} % https://christophm.github.io/interpretable-ml-book/

@inproceedings{mittelstadt2019explaining,
	title={Explaining explanations in AI},
	author={Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
	booktitle={Proceedings of the conference on fairness, accountability, and transparency},
	pages={279--288},
	year={2019},
	organization={ACM}
} % https://arxiv.org/abs/1811.01439v1


@article{uberselfdrivingcar,
	title={Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam.},
	author={Caitlin O'Hara},
	journal={Ny times},
	year={2018}
}

@book{Goodfellow-et-al-2016,
	title={Deep Learning},
	author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	publisher={MIT Press},
	note={\url{http://www.deeplearningbook.org}},
	year={2016}
}

@article{goodman2017european,
	title={European Union regulations on algorithmic decision-making.},
	author={Goodman, Bryce and Flaxman, Seth R},
	journal={,},
	year={2017}
}

@article{doshi2017accountability,
	title={Accountability of AI under the law: The role of explanation},
	author={Doshi-Velez, Finale and Kortz, Mason and Budish, Ryan and Bavitz, Chris and Gershman, Sam and O'Brien, David and Schieber, Stuart and Waldo, James and Weinberger, David and Wood, Alexandra},
	journal={arXiv preprint arXiv:1711.01134},
	year={2017}
}

@article{shapley1953value,
	title={A value for n-person games},
	author={Shapley, Lloyd S},
	journal={Contributions to the Theory of Games},
	volume={2},
	number={28},
	pages={307--317},
	year={1953}
}







%%%%%%%%%%%%%%%%%%%%%% Section Survey
@article{guidotti2018survey,
	title={A survey of methods for explaining black box models},
	author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
	journal={ACM computing surveys (CSUR)},
	volume={51},
	number={5},
	pages={93},
	year={2018},
	publisher={ACM}
} % https://arxiv.org/abs/1802.01933v3

@article{du2018techniques,
	title={Techniques for interpretable machine learning},
	author={Du, Mengnan and Liu, Ninghao and Hu, Xia},
	journal={arXiv preprint arXiv:1808.00033},
	year={2018}
} % https://arxiv.org/abs/1808.00033v3

@article{murdoch2019interpretable,
	title={Interpretable machine learning: definitions, methods, and applications},
	author={Murdoch, W James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
	journal={arXiv preprint arXiv:1901.04592},
	year={2019}
} % https://arxiv.org/abs/1901.04592v1

@article{zhang2019machine,
	title={Machine Learning Testing: Survey, Landscapes and Horizons},
	author={Zhang, Jie M and Harman, Mark and Ma, Lei and Liu, Yang},
	journal={arXiv preprint arXiv:1906.10742},
	year={2019}
} % https://arxiv.org/abs/1906.10742v1






%%%%%%%%%%%%%%%%%%%%%% Section Explnation Evaluation
@article{britton2019vine,
	title={VINE: Visualizing Statistical Interactions in Black Box Models},
	author={Britton, Matthew},
	journal={arXiv preprint arXiv:1904.00561},
	year={2019} 
} % https://arxiv.org/abs/1904.00561v1

@article{alvarez2018robustness,
	title={On the robustness of interpretability methods},
	author={Alvarez-Melis, David and Jaakkola, Tommi S},
	journal={arXiv preprint arXiv:1806.08049},
	year={2018}
} % https://arxiv.org/abs/1806.08049

@article{honegger2018shedding,
	title={Shedding Light on Black Box Machine Learning Algorithms: Development of an Axiomatic Framework to Assess the Quality of Methods that Explain Individual Predictions},
	author={Honegger, Milo},
	journal={arXiv preprint arXiv:1808.05054},
	year={2018}
} % https://arxiv.org/abs/1808.05054v1

@article{yeh2019sensitive,
	title={How Sensitive are Sensitivity-Based Explanations?},
	author={Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun Sai and Inouye, David and Ravikumar, Pradeep},
	journal={arXiv preprint arXiv:1901.09392},
	year={2019}
} % https://arxiv.org/abs/1901.09392

@article{plumb2019regularizing,
	title={Regularizing Black-box Models for Improved Interpretability},
	author={Plumb, Gregory and Al-Shedivat, Maruan and Xing, Eric and Talwalkar, Ameet},
	journal={arXiv preprint arXiv:1902.06787},
	year={2019}
} % https://arxiv.org/abs/1906.01431v1

@article{zheng2019analyzing,
	title={Analyzing the Interpretability Robustness of Self-Explaining Models},
	author={Zheng, Haizhong and Fernandes, Earlence and Prakash, Atul},
	journal={arXiv preprint arXiv:1905.12429},
	year={2019}
} % https://arxiv.org/abs/1905.12429v2

@article{gosiewska2019ibreakdown,
	title={iBreakDown: Uncertainty of Model Explanations for Non-additive Predictive Models},
	author={Gosiewska, Alicja and Biecek, Przemyslaw},
	journal={arXiv preprint arXiv:1903.11420},
	year={2019}
} % https://arxiv.org/abs/1903.11420 - iBreakDown






%%%%%%%%%%%%%%%%%%%%%% Section Explanation Method
@inproceedings{ribeiro2016should,
	title={Why should i trust you?: Explaining the predictions of any classifier},
	author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
	pages={1135--1144},
	year={2016},
	organization={ACM}
} % https://arxiv.org/abs/1602.04938v3 - LIME Method

@inproceedings{lundberg2017unified,
	title={A unified approach to interpreting model predictions},
	author={Lundberg, Scott M and Lee, Su-In},
	booktitle={Advances in Neural Information Processing Systems},
	pages={4765--4774},
	year={2017}
} % https://arxiv.org/abs/1705.07874 - SHAP Method

@article{adhikari2018example,
	title={Example and Feature importance-based Explanations for Black-box Machine Learning Models},
	author={Adhikari, Ajaya and Tax, DM and Satta, Riccardo and Fath, Matthias},
	journal={arXiv preprint arXiv:1812.09044},
	year={2018}
} % https://arxiv.org/abs/1812.09044 - LEAFAGE Method

@article{dhurandhar2019model,
	title={Model Agnostic Contrastive Explanations for Structured Data},
	author={Dhurandhar, Amit and Pedapati, Tejaswini and Balakrishnan, Avinash and Chen, Pin-Yu and Shanmugam, Karthikeyan and Puri, Ruchir},
	journal={arXiv preprint arXiv:1906.00117},
	year={2019}
} % https://arxiv.org/abs/1906.00117 - Agnostic Contrastive Method

@article{van2018contrastive,
	title={Contrastive explanations with local foil trees},
	author={van der Waa, Jasper and Robeer, Marcel and van Diggelen, Jurriaan and Brinkhuis, Matthieu and Neerincx, Mark},
	journal={arXiv preprint arXiv:1806.07470},
	year={2018}
} % https://arxiv.org/abs/1806.07470 - FOIL

@inproceedings{alvarez2018towards,
	title={Towards robust interpretability with self-explaining neural networks},
	author={Alvarez-Melis, David and Jaakkola, Tommi S},
	booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
	pages={7786--7795},
	year={2018},
	organization={Curran Associates Inc.} 
} % https://arxiv.org/abs/1806.07538v2 - SENN

@inproceedings{fong2017interpretable,
	title={Interpretable explanations of black boxes by meaningful perturbation},
	author={Fong, Ruth C and Vedaldi, Andrea},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={3429--3437},
	year={2017}
} % https://arxiv.org/abs/1704.03296v3

@article{zafar2019dlime,
	title={DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems},
	author={Zafar, Muhammad Rehman and Khan, Naimul Mefraz},
	journal={arXiv preprint arXiv:1906.10263},
	year={2019}
} % https://arxiv.org/abs/1906.10263  - DLIME

@article{ancona2017towards,
	title={Towards better understanding of gradient-based attribution methods for deep neural networks},
	author={Ancona, Marco and Ceolini, Enea and {\"O}ztireli, Cengiz and Gross, Markus},
	journal={arXiv preprint arXiv:1711.06104},
	year={2017}
} % https://arxiv.org/pdf/1711.06104.pdf - DeepExplain

@misc{simonyan2013deep,
	title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
	year={2013},
	eprint={1312.6034},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
} %  https://arxiv.org/pdf/1312.6034.pdf, - Saliency

@article{shrikumar2016not,
	title={Not just a black box: Learning important features through propagating activation differences},
	author={Shrikumar, Avanti and Greenside, Peyton and Shcherbina, Anna and Kundaje, Anshul},
	journal={arXiv preprint arXiv:1605.01713},
	year={2016} 
} % https://arxiv.org/pdf/1605.01713.pdf - Grads-Input (DeepLIFT 2016)

@inproceedings{sundararajan2017axiomatic,
	title={Axiomatic attribution for deep networks},
	author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={3319--3328},
	year={2017},
	organization={JMLR. org}
} % https://arxiv.org/pdf/1703.01365.pdf - Integrated Gradients

@article{bach2015pixel,
	title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
	author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
	journal={PloS one},
	volume={10},
	number={7},
	pages={e0130140},
	year={2015},
	publisher={Public Library of Science}
} % https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140 - e-LRP

@inproceedings{shrikumar2017learning,
	title={Learning important features through propagating activation differences},
	author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={3145--3153},
	year={2017},
	organization={JMLR. org}
} % http://proceedings.mlr.press/v70/shrikumar17a.html - DeepLIFT 2017

@inproceedings{zeiler2014visualizing,
	title={Visualizing and understanding convolutional networks},
	author={Zeiler, Matthew D and Fergus, Rob},
	booktitle={European conference on computer vision},
	pages={818--833},
	year={2014},
	organization={Springer}
} % https://arxiv.org/pdf/1311.2901.pdf - Occlusion

@article{zintgraf2017visualizing,
	title={Visualizing deep neural network decisions: Prediction difference analysis},
	author={Zintgraf, Luisa M and Cohen, Taco S and Adel, Tameem and Welling, Max},
	journal={arXiv preprint arXiv:1702.04595},
	year={2017}
} % https://arxiv.org/abs/1702.04595 -- Occlusion reference






%%%%%%%%%%%%%%%%%%%%%% Section Explanation Regularization
@article{ross2018training,
	title={Training Machine Learning Models by Regularizing their Explanations},
	author={Ross, Andrew Slavin},
	journal={arXiv preprint arXiv:1810.00869},
	year={2018}
} % Training Machine Learning Models by Regularizing their Explanations - Thesis Paper


